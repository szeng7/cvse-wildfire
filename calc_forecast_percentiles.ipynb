{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "FEATURES = [\n",
    "    \"u_component_of_wind_10m_above_ground\",\n",
    "    \"v_component_of_wind_10m_above_ground\",\n",
    "    \"temperature_2m_above_ground\",\n",
    "    \"precipitable_water_entire_atmosphere\",\n",
    "]\n",
    "\n",
    "TILE_SIZE = (128, 128)\n",
    "feature_values = {key: [] for key in FEATURES}\n",
    "\n",
    "tfrecord_files = sorted(glob.glob(\"./data/data_full_train__*.tfrecord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]2025-04-23 23:30:13.195214: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.195575: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.195785: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.195998: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.196323: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.196540: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.197672: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.198001: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "2025-04-23 23:30:13.204400: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]2025-04-23 23:30:13.204679: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m dataset = tf.data.TFRecordDataset(tfrecord_path)\n\u001b[32m     14\u001b[39m dataset = dataset.map(parse_fn)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cvse/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001b[39m, in \u001b[36mOwnedIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    808\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m errors.OutOfRangeError:\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cvse/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001b[39m, in \u001b[36mOwnedIterator._next_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context.execution_mode(context.SYNC):\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m   ret = \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    777\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    778\u001b[39m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[32m    779\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._element_spec._from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cvse/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[39m, in \u001b[36miterator_get_next\u001b[39m\u001b[34m(iterator, output_types, output_shapes, name)\u001b[39m\n\u001b[32m   3084\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3086\u001b[39m   \u001b[43m_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3087\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   3088\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cvse/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} Key: precipitable_water_entire_atmosphere.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "def get_feature_spec():\n",
    "    return {\n",
    "        key: tf.io.FixedLenFeature(shape=TILE_SIZE, dtype=tf.float32)\n",
    "        for key in FEATURES\n",
    "    }\n",
    "\n",
    "def parse_fn(example_proto):\n",
    "    features = tf.io.parse_single_example(example_proto, get_feature_spec())\n",
    "    return features\n",
    "\n",
    "#iterate over paths and get values\n",
    "for tfrecord_path in tqdm(tfrecord_files):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.map(parse_fn)\n",
    "\n",
    "    for sample in dataset:\n",
    "        for key in FEATURES:\n",
    "            arr = sample[key].numpy().flatten()\n",
    "            feature_values[key].append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all values\n",
    "final_stats = {}\n",
    "for key in FEATURES:\n",
    "    all_vals = np.concatenate(feature_values[key])\n",
    "    p001 = np.percentile(all_vals, 0.1)\n",
    "    p999 = np.percentile(all_vals, 99.9)\n",
    "    mean = np.mean(all_vals)\n",
    "    std = np.std(all_vals)\n",
    "\n",
    "    final_stats[key] = {\n",
    "        \"min_clip\": float(p001),\n",
    "        \"max_clip\": float(p999),\n",
    "        \"mean\": float(mean),\n",
    "        \"std\": float(std),\n",
    "    }\n",
    "\n",
    "# Print final stats\n",
    "for key, stats in final_stats.items():\n",
    "    print(f\"{key}: {stats}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
